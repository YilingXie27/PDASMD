{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 80,
     "status": "ok",
     "timestamp": 1649868617099,
     "user": {
      "displayName": "Mia L",
      "userId": "10188914046469678038"
     },
     "user_tz": 240
    },
    "id": "cYsKgc4SDm6h",
    "outputId": "9969cb6b-c78e-4d28-aa7c-4c260d6b0faf"
   },
   "outputs": [],
   "source": [
    "# If run experiment on Google Colab, upload all code to Google Drive, and run this chunk to set the working directory to where the code is located at.\n",
    "# Otherwise, just set the working directory to your local directory where you store the code. \n",
    "\n",
    "# Set the working directory to a folder in my Google Drive. \n",
    "import os \n",
    "# the base Google Drive directory\n",
    "root_dir = \"/content/drive/My Drive/\"\n",
    "\n",
    "# set it to where your project files are saved\n",
    "project_folder = \"mirror_experiment\"\n",
    "\n",
    "def create_and_set_working_directory(project_folder):\n",
    "  # check if the project folder exists. if not, it will be created.\n",
    "  if os.path.isdir(root_dir + project_folder) == False:\n",
    "    os.mkdir(root_dir + project_folder)\n",
    "    print(root_dir + project_folder + ' did not exist but was created.')\n",
    "\n",
    "  # change the OS to use the project folder as the working directory\n",
    "  os.chdir(root_dir + project_folder)\n",
    "\n",
    "  print('\\nYour working directory was changed to ' + root_dir + project_folder )\n",
    "\n",
    "create_and_set_working_directory(project_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8477,
     "status": "ok",
     "timestamp": 1649868626771,
     "user": {
      "displayName": "Mia L",
      "userId": "10188914046469678038"
     },
     "user_tz": 240
    },
    "id": "-8w6iLYUTi28"
   },
   "outputs": [],
   "source": [
    "#### import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import dist_img_m, synthetic_img_input\n",
    "from algos import PDASMD_w_rounding, APDAGD_w_rounding, Sinkhorn_w_rounding, AAM_w_rounding\n",
    "from algos import Stochastic_sinkhorn_w_rounding, APDRCD_w_rounding\n",
    "from scipy.stats import linregress\n",
    "import pickle\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "#%% import mnist images\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzhW82TWSwnY"
   },
   "source": [
    "#1. Compare PDASMD with other algorithms on synthetic data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "executionInfo": {
     "elapsed": 1012,
     "status": "ok",
     "timestamp": 1649868631198,
     "user": {
      "displayName": "Mia L",
      "userId": "10188914046469678038"
     },
     "user_tz": 240
    },
    "id": "N8m_UJm2V3as",
    "outputId": "e3e0009f-95e9-48a1-e3cf-0282728be09d"
   },
   "outputs": [],
   "source": [
    "#%% generating the images\n",
    "alpha_list = []\n",
    "beta_list = []\n",
    "C_list = []\n",
    "m_list = [3,5,7,9,12]\n",
    "size_list = list(map(lambda x: x**2,m_list))\n",
    "reps_each_m = 5\n",
    "num_m = len(m_list)\n",
    "np.random.seed(1010)\n",
    "seed_list_1 = np.random.choice(range(reps_each_m*100),reps_each_m)\n",
    "seed_list_2 = np.random.choice(range(reps_each_m*100,reps_each_m*200),reps_each_m)\n",
    "\n",
    "for m in m_list:\n",
    "    for seed1,seed2 in zip(seed_list_1,seed_list_2):\n",
    "        alpha_list.append( synthetic_img_input(m, seed = seed1)  ) \n",
    "        beta_list.append( synthetic_img_input(m, seed = seed2)  ) \n",
    "    C_list.append(dist_img_m(m))\n",
    "\n",
    "#%%% parameter list\n",
    "epsilons = [.05] * reps_each_m * num_m\n",
    "sizes = np.repeat(size_list, reps_each_m)\n",
    "idxes_c = np.repeat(range(num_m), reps_each_m)\n",
    "idxes_dist = range(num_m * reps_each_m)\n",
    "settings = list(zip(epsilons,sizes,idxes_c,idxes_dist))\n",
    "\n",
    "#%% example images to take a look\n",
    "m_list = [7,9,11,12]\n",
    "\n",
    "fig,ax = plt.subplots(2,2,figsize = (4,4))\n",
    "#plt.tight_layout()\n",
    "ax = ax.ravel()\n",
    "for i,m in enumerate(m_list):\n",
    "    temp = synthetic_img_input(m,seed = 5735)\n",
    "    image = Image.fromarray(np.array(temp.reshape(m,m)*255/max(temp),np.uint8))\n",
    "    ax[i].imshow(image,cmap = 'Blues')\n",
    "    ax[i].set_title(r\"{} * {}\".format(m,m))\n",
    "    ax[i].axis('off')\n",
    "  \n",
    "plt.savefig(\"results/sample_image.pdf\", format=\"pdf\", bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1366466,
     "status": "ok",
     "timestamp": 1649869999591,
     "user": {
      "displayName": "Mia L",
      "userId": "10188914046469678038"
     },
     "user_tz": 240
    },
    "id": "dkqS_XQ6VB83",
    "outputId": "c90cbd39-66d8-47e9-cac5-52995bd9d3a4"
   },
   "outputs": [],
   "source": [
    "#%% calculate epsilon solution, the goal is to compare the total computation\n",
    "PDASMD_result = []\n",
    "i = 1\n",
    "for epsilon, size, idx_c, idx_dist in settings:\n",
    "    print(\"running {}/{} experiment\".format(i,len(settings)))\n",
    "    i += 1\n",
    "    solution, computations, time = PDASMD_w_rounding(\n",
    "        alpha = alpha_list[idx_dist], beta = beta_list[idx_dist],\n",
    "        C = C_list[idx_c], epsilon = epsilon, Size = size, \n",
    "        inner_iters = size, MD = True)\n",
    "    PDASMD_result.append([solution, computations, time])\n",
    "\n",
    "#%% \n",
    "PDASGD_result = []\n",
    "i = 1\n",
    "for epsilon, size, idx_c, idx_dist in settings:\n",
    "    print(\"running {}/{} experiment\".format(i,len(settings)))\n",
    "    i += 1\n",
    "    solution, computations, time = PDASMD_w_rounding(\n",
    "        alpha = alpha_list[idx_dist], beta = beta_list[idx_dist],\n",
    "        C = C_list[idx_c], epsilon = epsilon, Size = size, \n",
    "        inner_iters = size, MD = False)\n",
    "    PDASGD_result.append([solution, computations, time])\n",
    "#%%\n",
    "APDAGD_result = []\n",
    "i = 1\n",
    "for epsilon, size, idx_c, idx_dist in settings:\n",
    "    print(\"running {}/{} experiment\".format(i,len(settings)))\n",
    "    i += 1\n",
    "    solution, computations, time = APDAGD_w_rounding(\n",
    "        epsilon = epsilon, Size = size, C = C_list[idx_c],\n",
    "        alpha = alpha_list[idx_dist], beta = beta_list[idx_dist])\n",
    "    APDAGD_result.append([solution, computations, time])\n",
    "#%%\n",
    "AAM_result = []\n",
    "i = 1\n",
    "for epsilon, size, idx_c, idx_dist in settings:\n",
    "    print(\"running {}/{} experiment\".format(i,len(settings)))\n",
    "    i += 1\n",
    "    solution, computations, time = AAM_w_rounding(\n",
    "        epsilon = epsilon, Size = size, C = C_list[idx_c],\n",
    "        alpha = alpha_list[idx_dist], beta = beta_list[idx_dist])\n",
    "    AAM_result.append([solution, computations, time])\n",
    "#%%\n",
    "Sinkhorn_result = []\n",
    "i = 1\n",
    "for epsilon, size, idx_c, idx_dist in settings:\n",
    "    print(\"running {}/{} experiment\".format(i,len(settings)))\n",
    "    i += 1\n",
    "    solution, computations, time = Sinkhorn_w_rounding(\n",
    "        epsilon = epsilon, Size = size, C = C_list[idx_c],\n",
    "        alpha = alpha_list[idx_dist], beta = beta_list[idx_dist])\n",
    "    Sinkhorn_result.append([solution, computations, time])\n",
    "\n",
    "#%% Uncomment to run APDRCD, it is pretty slow.\n",
    "#APDRCD_result = []\n",
    "#i = 1\n",
    "#for epsilon, size, idx_c, idx_dist in settings:\n",
    "#    print(\"running {}/{} experiment\".format(i,len(settings)))\n",
    "#    i += 1\n",
    "#    solution, computations, time = APDRCD_w_rounding(\n",
    "#        epsilon = epsilon, Size = size, C = C_list[idx_c],\n",
    "#        alpha = alpha_list[idx_dist], beta = beta_list[idx_dist])\n",
    "#    APDRCD_result.append([solution, computations, time])\n",
    "    \n",
    "#%%\n",
    "Stoc_Sinkhorn_result = []\n",
    "\n",
    "i = 1\n",
    "for epsilon, size, idx_c, idx_dist in settings:\n",
    "    print(\"running {}/{} experiment\".format(i,len(settings)))\n",
    "    i += 1\n",
    "    solution, computations, time = Stochastic_sinkhorn_w_rounding(\n",
    "        epsilon = epsilon, Size = size, C = C_list[idx_c],\n",
    "        alpha = alpha_list[idx_dist], beta = beta_list[idx_dist])\n",
    "    Stoc_Sinkhorn_result.append([solution, computations, time])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1RL05rifKFfcrFaagHgP5NpEVeEkimK6P"
    },
    "executionInfo": {
     "elapsed": 10791,
     "status": "ok",
     "timestamp": 1649870494024,
     "user": {
      "displayName": "Mia L",
      "userId": "10188914046469678038"
     },
     "user_tz": 240
    },
    "id": "UkO9BFxHWBNP",
    "outputId": "4811e286-1370-4f62-ee39-c042563491ea"
   },
   "outputs": [],
   "source": [
    "#%%plot the results\n",
    "PDASMD_result_cleaned = pd.DataFrame([[i[0][1],i[0][2],i[1]] for i in zip(PDASMD_result,np.repeat(size_list, reps_each_m))])\n",
    "PDASMD_result_cleaned.columns = ['computations','time','n']\n",
    "#%%\n",
    "APDAGD_result_cleaned = pd.DataFrame([[i[0][1],i[0][2],i[1]] for i in zip(APDAGD_result,np.repeat(size_list, reps_each_m))])\n",
    "APDAGD_result_cleaned.columns = ['computations','time','n']\n",
    "\n",
    "AAM_result_cleaned = pd.DataFrame([[i[0][1],i[0][2],i[1]] for i in zip(AAM_result,np.repeat(size_list, reps_each_m))])\n",
    "AAM_result_cleaned.columns = ['computations','time','n']\n",
    "\n",
    "Sinkhorn_result_cleaned = pd.DataFrame([[i[0][1], i[0][2],i[1]] for i in zip(Sinkhorn_result,np.repeat(size_list, reps_each_m))])\n",
    "Sinkhorn_result_cleaned.columns = ['computations','time','n']\n",
    "\n",
    "#%% plot the comparison with deterministic algorithms\n",
    "\n",
    "plt.figure(dpi=1000)\n",
    "\n",
    "\n",
    "lr_smd  = linregress(np.log(size_list), np.log(PDASMD_result_cleaned.groupby('n').mean()['computations']))\n",
    "plt.plot(np.log(size_list), np.log(PDASMD_result_cleaned.groupby('n').mean()['computations']),\n",
    "         label=\"PDASMD, slope = {:.2f}\".format(lr_smd[0]),color='darkgreen', marker ='o',markersize = 6,lw=1)\n",
    "plt.fill_between(np.log(size_list), np.log(PDASMD_result_cleaned.groupby('n').min()['computations']),\n",
    "         np.log(PDASMD_result_cleaned.groupby('n').max()['computations']),\n",
    "         color='darkgreen', alpha = 0.2)\n",
    "\n",
    "lr_gd  = linregress(np.log(size_list), np.log(APDAGD_result_cleaned.groupby('n').mean()['computations']))\n",
    "plt.plot(np.log(size_list), np.log(APDAGD_result_cleaned.groupby('n').mean()['computations']),label=\"APDAGD, slope = {:.2f}\".format(lr_gd[0]),color='pink', marker ='o',markersize = 6,lw=1)\n",
    "plt.fill_between(np.log(size_list), np.log(APDAGD_result_cleaned.groupby('n').min()['computations']),\n",
    "         np.log(APDAGD_result_cleaned.groupby('n').max()['computations']),\n",
    "         color='pink', alpha = 0.2)\n",
    "\n",
    "lr_aam  = linregress(np.log(size_list), np.log(AAM_result_cleaned.groupby('n').mean()['computations']))\n",
    "plt.plot(np.log(size_list), np.log(AAM_result_cleaned.groupby('n').mean()['computations']),label=\"AAM, slope = {:.2f}\".format(lr_aam[0]),color='blue', marker ='o',markersize = 6,lw=1)\n",
    "plt.fill_between(np.log(size_list), np.log(AAM_result_cleaned.groupby('n').min()['computations']),\n",
    "         np.log(AAM_result_cleaned.groupby('n').max()['computations']),\n",
    "         color='blue', alpha = 0.2)\n",
    "\n",
    "lr_sin  = linregress(np.log(size_list), np.log(Sinkhorn_result_cleaned.groupby('n').mean()['computations']))\n",
    "plt.plot(np.log(size_list), np.log(Sinkhorn_result_cleaned.groupby('n').mean()['computations']),label=\"Sinkhorn, slope = {:.2f}\".format(lr_sin[0]),color='violet', marker ='o',markersize = 6,lw=1)\n",
    "plt.fill_between(np.log(size_list), np.log(Sinkhorn_result_cleaned.groupby('n').min()['computations']),\n",
    "         np.log(Sinkhorn_result_cleaned.groupby('n').max()['computations']),\n",
    "         color='violet', alpha = 0.2)\n",
    "#lr_gd  = linregress(np.log(size_list), np.log(PDASGD_result_cleaned.groupby('n').mean()['computations']))\n",
    "#plt.plot(np.log(size_list), np.log(PDASGD_result_cleaned.groupby('n').mean()['computations']),label=\"APDAGD, slope = {:.2f}\".format(lr_gd[0]),color='crimson', marker ='*',markersize = 3,lw=1)\n",
    "#plt.fill_between(np.log(size_list), np.log(PDASGD_result_cleaned.groupby('n').min()['computations']),\n",
    "#         np.log(PDASGD_result_cleaned.groupby('n').max()['computations']),\n",
    "#         color='crimson', alpha = 0.2)\n",
    "\n",
    "plt.xlabel(r'$ln(n)$',fontsize=20)\n",
    "plt.ylabel(r'$ln( \\# operation )$',fontsize=20) \n",
    "plt.legend(fontsize=13)\n",
    "plt.title(\"ln(number of operations) versus ln(n)\",fontsize=20)\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "plt.savefig(\"results/sys_compare_deter.pdf\", format=\"pdf\",bbox_inches = 'tight')\n",
    "\n",
    "\n",
    "\n",
    "#%% plot the comparison with stochastic algorithms\n",
    "\n",
    "PDASGD_result_cleaned = pd.DataFrame([[i[0][1],i[0][2],i[1]] for i in zip(PDASGD_result,np.repeat(size_list, reps_each_m))])\n",
    "PDASGD_result_cleaned.columns = ['computations','time','n']\n",
    "\n",
    "#APDRCD_result_cleaned = pd.DataFrame([[i[0][1],i[0][2],i[1]] for i in zip(APDRCD_result,np.repeat(size_list, reps_each_m))])\n",
    "#APDRCD_result_cleaned.columns = ['computations','time','n']\n",
    "\n",
    "Sto_Sink_result_cleaned = pd.DataFrame([[i[0][1],i[0][2],i[1]] for i in zip(Stoc_Sinkhorn_result,np.repeat(size_list, reps_each_m))])\n",
    "Sto_Sink_result_cleaned.columns = ['computations','time','n']\n",
    "#%%\n",
    "\n",
    "plt.figure(dpi=1000)\n",
    "\n",
    "\n",
    "lr_smd  = linregress(np.log(size_list), np.log(PDASMD_result_cleaned.groupby('n').mean()['computations']))\n",
    "plt.plot(np.log(size_list), np.log(PDASMD_result_cleaned.groupby('n').mean()['computations']),\n",
    "         label=\"PDASMD, slope = {:.2f}\".format(lr_smd[0]),color='darkgreen', marker ='o',markersize = 6,lw=1)\n",
    "plt.fill_between(np.log(size_list), np.log(PDASMD_result_cleaned.groupby('n').min()['computations']),\n",
    "         np.log(PDASMD_result_cleaned.groupby('n').max()['computations']),\n",
    "         color='darkgreen', alpha = 0.2)\n",
    "\n",
    "lr_sgd  = linregress(np.log(size_list), np.log(PDASGD_result_cleaned.groupby('n').mean()['computations']))\n",
    "plt.plot(np.log(size_list), np.log(PDASGD_result_cleaned.groupby('n').mean()['computations']),\n",
    "         label=\"PDASGD, slope = {:.2f}\".format(lr_sgd[0]),color='pink', marker ='*',markersize = 6,lw=1)\n",
    "plt.fill_between(np.log(size_list), np.log(PDASGD_result_cleaned.groupby('n').min()['computations']),\n",
    "         np.log(PDASGD_result_cleaned.groupby('n').max()['computations']),\n",
    "         color='pink', alpha = 0.2)\n",
    "\n",
    "#lr_rcd  = linregress(np.log(size_list), np.log(APDRCD_result_cleaned.groupby('n').mean()['computations']))\n",
    "#plt.plot(np.log(size_list), np.log(APDRCD_result_cleaned.groupby('n').mean()['computations']), label=\"APDRCD, slope = {:.2f}\".format(lr_rcd[0]),color='blue', marker ='',markersize = 6,lw=1)\n",
    "#plt.fill_between(np.log(size_list), np.log(APDRCD_result_cleaned.groupby('n').min()['computations']),\n",
    "#         np.log(APDRCD_result_cleaned.groupby('n').max()['computations']),\n",
    "#         color='blue', alpha = 0.2)\n",
    "\n",
    "lr_ss  = linregress(np.log(size_list), np.log(Sto_Sink_result_cleaned.groupby('n').mean()['computations']))\n",
    "plt.plot(np.log(size_list), np.log(Sto_Sink_result_cleaned.groupby('n').mean()['computations']),\n",
    "         label=\"Stochastic Sinkhorn, slope = {:.2f}\".format(lr_ss[0]),color='violet', marker ='o',markersize = 6,lw=1)\n",
    "plt.fill_between(np.log(size_list), np.log(Sto_Sink_result_cleaned.groupby('n').min()['computations']),\n",
    "         np.log(Sto_Sink_result_cleaned.groupby('n').max()['computations']),\n",
    "         color='violet', alpha = 0.2)\n",
    "\n",
    "\n",
    "plt.xlabel(r'$ln(n)$',fontsize=20)\n",
    "plt.ylabel(r'$ln( \\# operation )$',fontsize=20) \n",
    "plt.legend(fontsize=13)\n",
    "plt.title(\"ln(number of operations) versus ln(n)\",fontsize=20)\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "plt.savefig(\"results/sys_compare_stoc.pdf\", format=\"pdf\",bbox_inches = 'tight')\n",
    "\n",
    "#%% save the data and results\n",
    "\n",
    "results = {'alpha_list': alpha_list, 'beta_list': beta_list, 'C_list': C_list, \n",
    "    'PDASMD_result': PDASMD_result, 'PDASGD_result': PDASGD_result, \n",
    "           'APDAGD_result': APDAGD_result, 'AAM_result': AAM_result, \n",
    "           'Sinkhorn_result': Sinkhorn_result, 'Stoc_Sinkhorn_result': Stoc_Sinkhorn_result}\n",
    "  \n",
    "try:\n",
    "    file = open('results/comparison_syn', 'wb')\n",
    "    pickle.dump(results,file)\n",
    "    file.close()\n",
    "  \n",
    "except:\n",
    "    print(\"Something went wrong\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIlArxwvTDrI"
   },
   "source": [
    "#2. Evaluate the performance of PDASMD-B on synthetic data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 130,
     "status": "ok",
     "timestamp": 1649870503006,
     "user": {
      "displayName": "Mia L",
      "userId": "10188914046469678038"
     },
     "user_tz": 240
    },
    "id": "OzgceRsTWrtA"
   },
   "outputs": [],
   "source": [
    "#%% generating the images\n",
    "alpha_list = []\n",
    "beta_list = []\n",
    "C_list = []\n",
    "m_list = [8,10,12]\n",
    "size_list = list(map(lambda x: x**2,m_list))\n",
    "reps_each_m = 5\n",
    "num_m = len(m_list)\n",
    "np.random.seed(1010)\n",
    "seed_list_1 = np.random.choice(range(reps_each_m*100),reps_each_m)\n",
    "seed_list_2 = np.random.choice(range(reps_each_m*100,reps_each_m*200),reps_each_m)\n",
    "\n",
    "for m in m_list:\n",
    "    for seed1,seed2 in zip(seed_list_1,seed_list_2):\n",
    "        alpha_list.append( synthetic_img_input(m, seed = seed1)  ) \n",
    "        beta_list.append( synthetic_img_input(m, seed = seed2)  ) \n",
    "    C_list.append(dist_img_m(m))\n",
    "\n",
    "#%%% parameter list\n",
    "epsilons = [.05] * reps_each_m * num_m\n",
    "sizes = np.repeat(size_list, reps_each_m)\n",
    "idxes_c = np.repeat(range(num_m), reps_each_m)\n",
    "idxes_dist = range(num_m * reps_each_m)\n",
    "\n",
    "batch_sizes = [i for i in range(2,49,8)]\n",
    "\n",
    "settings = []\n",
    "for epsilon, size, idx_c, idx_dist in list(zip(epsilons,sizes,idxes_c,idxes_dist)):\n",
    "    for batch_size in batch_sizes:\n",
    "        settings.append([epsilon, size, idx_c, idx_dist, batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1335776,
     "status": "ok",
     "timestamp": 1649871840459,
     "user": {
      "displayName": "Mia L",
      "userId": "10188914046469678038"
     },
     "user_tz": 240
    },
    "id": "7QdyUgitWgx7",
    "outputId": "ef56fc9c-4a4f-4452-b4ff-e7518ba48542"
   },
   "outputs": [],
   "source": [
    "#%% calculate epsilon solution, the goal is to compare the total computation\n",
    "PDASMD_result_batch = []\n",
    "i = 1\n",
    "for epsilon, size, idx_c, idx_dist, batch_size in settings:\n",
    "    print(\"Running {}/{} experiment\".format(i,len(settings)))\n",
    "    i += 1\n",
    "    solution, computations, time = PDASMD_w_rounding(\n",
    "        alpha = alpha_list[idx_dist], beta = beta_list[idx_dist],\n",
    "        C = C_list[idx_c], epsilon = epsilon, Size = size, \n",
    "        inner_iters = size//batch_size, batchsize = batch_size, MD = True)\n",
    "    PDASMD_result_batch.append([solution, computations, time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 10172,
     "status": "ok",
     "timestamp": 1649871936870,
     "user": {
      "displayName": "Mia L",
      "userId": "10188914046469678038"
     },
     "user_tz": 240
    },
    "id": "S4LBFAaaWvkp",
    "outputId": "ccd0e8b1-0aed-40db-8256-e754aa2191d4"
   },
   "outputs": [],
   "source": [
    "#%%plot the results\n",
    "PDASMD_result_batch_cleaned = pd.DataFrame([[i[0][1],i[0][2],i[1][1],i[1][4]] for i in zip(PDASMD_result_batch,settings)])\n",
    "PDASMD_result_batch_cleaned.columns = ['computations','time','n','batchsize']\n",
    "\n",
    "#%%\n",
    "plt.figure(dpi=1000)\n",
    "\n",
    "PDASMD_result_batch_mean = np.log(PDASMD_result_batch_cleaned.groupby(['n','batchsize']).mean()['computations'])\n",
    "PDASMD_result_batch_min = np.log(PDASMD_result_batch_cleaned.groupby(['n','batchsize']).min()['computations'])\n",
    "PDASMD_result_batch_max = np.log(PDASMD_result_batch_cleaned.groupby(['n','batchsize']).max()['computations'])\n",
    "#%%\n",
    "for n in size_list:\n",
    "    lr  = linregress(np.log(batch_sizes),PDASMD_result_batch_mean.loc[n] )\n",
    "    \n",
    "    plt.plot(np.log(batch_sizes), PDASMD_result_batch_mean.loc[n],label=\"n = {}, slope = {:.2f}\".format(n,lr[0]), marker ='o',markersize = 6,lw=1)\n",
    "    plt.fill_between(np.log(batch_sizes),PDASMD_result_batch_min.loc[n] ,\n",
    "             PDASMD_result_batch_max.loc[n], alpha = 0.2)\n",
    "\n",
    "plt.xlabel(r'$ln(batchsize)$',fontsize=20)\n",
    "plt.ylabel(r'$ln( \\# operation )$',fontsize=20) \n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"ln(number of operations) versus ln(batchsize)\",fontsize=20)\n",
    "\n",
    "plt.savefig(\"results/sys_batch_computation.pdf\", format=\"pdf\", bbox_inches = 'tight')\n",
    "\n",
    "#%%\n",
    "\n",
    "plt.figure(dpi=1000)\n",
    "\n",
    "\n",
    "PDASMD_result_batch_mean = np.log(PDASMD_result_batch_cleaned.groupby(['n','batchsize']).mean()['time'])\n",
    "PDASMD_result_batch_min = np.log(PDASMD_result_batch_cleaned.groupby(['n','batchsize']).min()['time'])\n",
    "PDASMD_result_batch_max = np.log(PDASMD_result_batch_cleaned.groupby(['n','batchsize']).max()['time'])\n",
    "\n",
    "for n in size_list:\n",
    "    #lr  = linregress(np.log(batch_sizes),PDASMD_result_batch_mean.loc[n] )\n",
    "    \n",
    "    plt.plot(np.log(batch_sizes), PDASMD_result_batch_mean.loc[n],label=\"n = {}\".format(n), marker ='o',markersize = 6,lw=1)\n",
    "    plt.fill_between(np.log(batch_sizes),PDASMD_result_batch_min.loc[n] ,\n",
    "             PDASMD_result_batch_max.loc[n], alpha = 0.2)\n",
    "\n",
    "plt.xlabel(r'$ln(batchsize)$',fontsize=20)\n",
    "plt.ylabel(r'$ln(running time)$',fontsize=20) \n",
    "plt.legend(fontsize=20)\n",
    "plt.title(\"ln(running time) versus ln(batchsize)\",fontsize=20)\n",
    "\n",
    "\n",
    "plt.savefig(\"results/sys_batch_time.pdf\", format=\"pdf\", bbox_inches = 'tight')\n",
    "\n",
    "#%% save the data and results\n",
    "\n",
    "results = {'alpha_list': alpha_list, 'beta_list': beta_list, 'C_list': C_list, \n",
    "    'PDASMD_result_batch': PDASMD_result_batch}\n",
    "  \n",
    "try:\n",
    "    file = open('results/comparison_syn_batch', 'wb')\n",
    "    pickle.dump(results,file)\n",
    "    file.close()\n",
    "  \n",
    "except:\n",
    "    print(\"Something went wrong\")\n",
    "    \n",
    "#%% Retrive the data\n",
    "results_file = open('results/comparison_syn_batch', 'rb')     \n",
    "results = pickle.load(results_file)\n",
    "PDASMD_result_batch = results['PDASMD_result_batch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oj71ZXhGTOtD"
   },
   "source": [
    "#3. Compare PDASMD with other algorithms on MNIST data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LK83aTsTEhRW"
   },
   "outputs": [],
   "source": [
    "### experiment setup\n",
    "alpha_list = []\n",
    "beta_list = []\n",
    "C_list = []\n",
    "m_list = [2,3,4,5,6,7,8,9,10]\n",
    "size_list = list(map(lambda x: x**2,m_list))\n",
    "reps_each_m = 5\n",
    "num_m = len(m_list)\n",
    "#### randomly sample from training images as the marginals\n",
    "#np.random.seed(3894)\n",
    "np.random.seed(1001)\n",
    "idx_list_1 = np.random.choice(range(30000),reps_each_m)\n",
    "idx_list_2 = np.random.choice(range(30000,60000),reps_each_m)\n",
    "\n",
    "#### marginal distribution list, where we reshape the mnist image to get different size marginals\n",
    "for m in m_list:\n",
    "    for idx1,idx2 in zip(idx_list_1,idx_list_2):\n",
    "      fig1 = Image.fromarray(x_train[idx1]).resize((m,m)) ### down scale the images\n",
    "      fig2 = Image.fromarray(x_train[idx2]).resize((m,m)) \n",
    "      fig1 = np.array(fig1, np.float64)\n",
    "      fig2 = np.array(fig2, np.float64) \n",
    "      idx = np.where(fig1 <= .15* np.max(fig1)) \n",
    "      fig1[idx] = .15* np.max(fig1) ### add background intensity\n",
    "      idx = np.where(fig2 <= .15* np.max(fig2)) \n",
    "      fig2[idx] = .15* np.max(fig2) ### add background intensity\n",
    "      fig1 /= fig1.sum()\n",
    "      fig2 /= fig2.sum()\n",
    "\n",
    "      alpha_list.append(fig1.reshape(-1,1)) \n",
    "      beta_list.append(fig2.reshape(-1,1)) \n",
    "    \n",
    "    C_list.append(dist_img_m(m))\n",
    "\n",
    "#%%% parameter list\n",
    "epsilons = [.1] * reps_each_m * num_m\n",
    "sizes = np.repeat(size_list, reps_each_m)\n",
    "idxes_c = np.repeat(range(num_m), reps_each_m)\n",
    "idxes_dist = range(num_m * reps_each_m)\n",
    "settings = list(zip(epsilons,sizes,idxes_c,idxes_dist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1648512139466,
     "user": {
      "displayName": "Mia L",
      "userId": "10188914046469678038"
     },
     "user_tz": 240
    },
    "id": "NO4XyA_12WgS",
    "outputId": "110424c4-f7c4-4cad-e3af-bfa0921f210a"
   },
   "outputs": [],
   "source": [
    "#### an example of down scaled image with added background intensity\n",
    "fig1 = Image.fromarray(x_train[idx1]).resize((m,m))\n",
    "idx = np.where(fig1 <= .15* np.max(fig1)) \n",
    "fig1 = np.array(fig1, np.float64)\n",
    "fig1[idx] = (.15* np.max(fig1))\n",
    "Image.fromarray(np.array(fig1,np.uint8)).resize((50,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122989,
     "status": "ok",
     "timestamp": 1648512262451,
     "user": {
      "displayName": "Mia L",
      "userId": "10188914046469678038"
     },
     "user_tz": 240
    },
    "id": "WmAD19kyI0N7",
    "outputId": "26d5b9cc-be48-4260-8ade-9261b725637b"
   },
   "outputs": [],
   "source": [
    "#%% calculate epsilon solution, the goal is to compare the total computation\n",
    "PDASMD_result = []\n",
    "i = 1\n",
    "for epsilon, size, idx_c, idx_dist in settings:\n",
    "    print(\"Running {}/{} experiment\".format(i,len(settings)))\n",
    "    i += 1\n",
    "    solution, computations, time = PDASMD_w_rounding(\n",
    "        alpha = alpha_list[idx_dist], beta = beta_list[idx_dist],\n",
    "        C = C_list[idx_c], epsilon = epsilon, Size = size, inner_iters = size, MD = True)\n",
    "    PDASMD_result.append([solution, computations, time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108773,
     "status": "ok",
     "timestamp": 1648512371218,
     "user": {
      "displayName": "Mia L",
      "userId": "10188914046469678038"
     },
     "user_tz": 240
    },
    "id": "mFrQJHkTI0uh",
    "outputId": "bb54ead8-41a4-4402-b67b-b19334f36ebb"
   },
   "outputs": [],
   "source": [
    "PDASGD_result = []\n",
    "i = 1\n",
    "for epsilon, size, idx_c, idx_dist in settings:\n",
    "    print(\"running {}/{} experiment\".format(i,len(settings)))\n",
    "    i += 1\n",
    "    solution, computations, time = PDASMD_w_rounding(\n",
    "        alpha = alpha_list[idx_dist], beta = beta_list[idx_dist],\n",
    "        C = C_list[idx_c], epsilon = epsilon, Size = size, \n",
    "        inner_iters = size, MD = False)\n",
    "    PDASGD_result.append([solution, computations, time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10647,
     "status": "ok",
     "timestamp": 1648512381855,
     "user": {
      "displayName": "Mia L",
      "userId": "10188914046469678038"
     },
     "user_tz": 240
    },
    "id": "UaoYx_f_s8Gj",
    "outputId": "ea0b4a25-291d-4ca9-8c65-b85d5417facb"
   },
   "outputs": [],
   "source": [
    "APDAGD_result = []\n",
    "i = 1\n",
    "for epsilon, size, idx_c, idx_dist in settings:\n",
    "    print(\"running {}/{} experiment\".format(i,len(settings)))\n",
    "    i += 1\n",
    "    solution, computations, time = APDAGD_w_rounding(\n",
    "        epsilon = epsilon, Size = size, C = C_list[idx_c],\n",
    "        alpha = alpha_list[idx_dist], beta = beta_list[idx_dist])\n",
    "    APDAGD_result.append([solution, computations, time])\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4924,
     "status": "ok",
     "timestamp": 1648512386771,
     "user": {
      "displayName": "Mia L",
      "userId": "10188914046469678038"
     },
     "user_tz": 240
    },
    "id": "Qw3VgBS4s_F0",
    "outputId": "1cdf7bca-b162-4418-ebd0-3e19dc6136f2"
   },
   "outputs": [],
   "source": [
    "\n",
    "AAM_result = []\n",
    "i = 1\n",
    "for epsilon, size, idx_c, idx_dist in settings:\n",
    "    print(\"running {}/{} experiment\".format(i,len(settings)))\n",
    "    i += 1\n",
    "    solution, computations, time = AAM_w_rounding(\n",
    "        epsilon = epsilon, Size = size, C = C_list[idx_c],\n",
    "        alpha = alpha_list[idx_dist], beta = beta_list[idx_dist])\n",
    "    AAM_result.append([solution, computations, time])\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4540,
     "status": "ok",
     "timestamp": 1648512391430,
     "user": {
      "displayName": "Mia L",
      "userId": "10188914046469678038"
     },
     "user_tz": 240
    },
    "id": "uS4AcE9ItA1x",
    "outputId": "441a6492-ec93-49a0-990c-5138721a700a"
   },
   "outputs": [],
   "source": [
    "Sinkhorn_result = []\n",
    "i = 1\n",
    "for epsilon, size, idx_c, idx_dist in settings:\n",
    "    print(\"running {}/{} experiment\".format(i,len(settings)))\n",
    "    i += 1\n",
    "    solution, computations, time = Sinkhorn_w_rounding(\n",
    "        epsilon = epsilon, Size = size, C = C_list[idx_c],\n",
    "        alpha = alpha_list[idx_dist], beta = beta_list[idx_dist])\n",
    "    Sinkhorn_result.append([solution, computations, time])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 202661,
     "status": "ok",
     "timestamp": 1648512594083,
     "user": {
      "displayName": "Mia L",
      "userId": "10188914046469678038"
     },
     "user_tz": 240
    },
    "id": "HB2WkevhiKn8",
    "outputId": "14e32f24-02b9-47e2-97ce-04d1b387ffed"
   },
   "outputs": [],
   "source": [
    "\n",
    "#%% skip APDRCD since it is too slow\n",
    "#APDRCD_result = []\n",
    "#i = 1\n",
    "#for epsilon, size, idx_c, idx_dist in settings:\n",
    "#    print(\"running {}/{} experiment\".format(i,len(settings)))\n",
    "#    i += 1\n",
    "#    solution, computations, time = APDRCD_w_rounding(\n",
    "#        epsilon = epsilon, Size = size, C = C_list[idx_c],\n",
    "#        alpha = alpha_list[idx_dist], beta = beta_list[idx_dist])\n",
    "#    APDRCD_result.append([solution, computations, time])\n",
    "    \n",
    "#%%\n",
    "Stoc_Sinkhorn_result = []\n",
    "\n",
    "i = 1\n",
    "for epsilon, size, idx_c, idx_dist in settings:\n",
    "    print(\"running {}/{} experiment\".format(i,len(settings)))\n",
    "    i += 1\n",
    "    solution, computations, time = Stochastic_sinkhorn_w_rounding(\n",
    "        epsilon = epsilon, Size = size, C = C_list[idx_c],\n",
    "        alpha = alpha_list[idx_dist], beta = beta_list[idx_dist])\n",
    "    Stoc_Sinkhorn_result.append([solution, computations, time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gLW4NonDYsvV"
   },
   "outputs": [],
   "source": [
    "#%% save the data and results\n",
    "\n",
    "results = {'alpha_list': alpha_list, 'beta_list': beta_list, 'C_list': C_list, \n",
    "    'PDASMD_result': PDASMD_result, 'PDASGD_result': PDASGD_result, \n",
    "           'APDAGD_result': APDAGD_result, 'AAM_result': AAM_result, \n",
    "           'Sinkhorn_result': Sinkhorn_result, 'Stoc_Sinkhorn_result': Stoc_Sinkhorn_result}\n",
    "  \n",
    "try:\n",
    "    file = open('results/comparison_mnist', 'wb')\n",
    "    pickle.dump(results,file)\n",
    "    file.close()\n",
    "  \n",
    "except:\n",
    "    print(\"Something went wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 915
    },
    "executionInfo": {
     "elapsed": 5715,
     "status": "ok",
     "timestamp": 1648512599793,
     "user": {
      "displayName": "Mia L",
      "userId": "10188914046469678038"
     },
     "user_tz": 240
    },
    "id": "b-mYQs8Ed1eT",
    "outputId": "8ba83561-7a52-447d-f13c-91c554266bb5"
   },
   "outputs": [],
   "source": [
    "#%%plot the results\n",
    "PDASMD_result_cleaned = pd.DataFrame([[i[0][1],i[0][2],i[1]] for i in zip(PDASMD_result,np.repeat(size_list, reps_each_m))])\n",
    "PDASMD_result_cleaned.columns = ['computations','time','n']\n",
    "#%%\n",
    "APDAGD_result_cleaned = pd.DataFrame([[i[0][1],i[0][2],i[1]] for i in zip(APDAGD_result,np.repeat(size_list, reps_each_m))])\n",
    "APDAGD_result_cleaned.columns = ['computations','time','n']\n",
    "\n",
    "AAM_result_cleaned = pd.DataFrame([[i[0][1],i[0][2],i[1]] for i in zip(AAM_result,np.repeat(size_list, reps_each_m))])\n",
    "AAM_result_cleaned.columns = ['computations','time','n']\n",
    "\n",
    "Sinkhorn_result_cleaned = pd.DataFrame([[i[0][1], i[0][2],i[1]] for i in zip(Sinkhorn_result,np.repeat(size_list, reps_each_m))])\n",
    "Sinkhorn_result_cleaned.columns = ['computations','time','n']\n",
    "\n",
    "#%% plot the comparison with deterministic algorithms\n",
    "\n",
    "plt.figure(dpi=1000)\n",
    "\n",
    "\n",
    "lr_smd  = linregress(np.log(size_list), np.log(PDASMD_result_cleaned.groupby('n').mean()['computations']))\n",
    "plt.plot(np.log(size_list), np.log(PDASMD_result_cleaned.groupby('n').mean()['computations']),\n",
    "         label=\"PDASMD, slope = {:.2f}\".format(lr_smd[0]),color='darkgreen', marker ='o',markersize = 6,lw=1)\n",
    "plt.fill_between(np.log(size_list), np.log(PDASMD_result_cleaned.groupby('n').min()['computations']),\n",
    "         np.log(PDASMD_result_cleaned.groupby('n').max()['computations']),\n",
    "         color='darkgreen', alpha = 0.2)\n",
    "\n",
    "lr_gd  = linregress(np.log(size_list), np.log(APDAGD_result_cleaned.groupby('n').mean()['computations']))\n",
    "plt.plot(np.log(size_list), np.log(APDAGD_result_cleaned.groupby('n').mean()['computations']),label=\"APDAGD, slope = {:.2f}\".format(lr_gd[0]),color='pink', marker ='o',markersize = 6,lw=1)\n",
    "plt.fill_between(np.log(size_list), np.log(APDAGD_result_cleaned.groupby('n').min()['computations']),\n",
    "         np.log(APDAGD_result_cleaned.groupby('n').max()['computations']),\n",
    "         color='pink', alpha = 0.2)\n",
    "\n",
    "lr_aam  = linregress(np.log(size_list), np.log(AAM_result_cleaned.groupby('n').mean()['computations']))\n",
    "plt.plot(np.log(size_list), np.log(AAM_result_cleaned.groupby('n').mean()['computations']),label=\"AAM, slope = {:.2f}\".format(lr_aam[0]),color='blue', marker ='o',markersize = 6,lw=1)\n",
    "plt.fill_between(np.log(size_list), np.log(AAM_result_cleaned.groupby('n').min()['computations']),\n",
    "         np.log(AAM_result_cleaned.groupby('n').max()['computations']),\n",
    "         color='blue', alpha = 0.2)\n",
    "\n",
    "lr_sin  = linregress(np.log(size_list), np.log(Sinkhorn_result_cleaned.groupby('n').mean()['computations']))\n",
    "plt.plot(np.log(size_list), np.log(Sinkhorn_result_cleaned.groupby('n').mean()['computations']),label=\"Sinkhorn, slope = {:.2f}\".format(lr_sin[0]),color='violet', marker ='o',markersize = 6,lw=1)\n",
    "plt.fill_between(np.log(size_list), np.log(Sinkhorn_result_cleaned.groupby('n').min()['computations']),\n",
    "         np.log(Sinkhorn_result_cleaned.groupby('n').max()['computations']),\n",
    "         color='violet', alpha = 0.2)\n",
    "#lr_gd  = linregress(np.log(size_list), np.log(PDASGD_result_cleaned.groupby('n').mean()['computations']))\n",
    "#plt.plot(np.log(size_list), np.log(PDASGD_result_cleaned.groupby('n').mean()['computations']),label=\"APDAGD, slope = {:.2f}\".format(lr_gd[0]),color='crimson', marker ='*',markersize = 3,lw=1)\n",
    "#plt.fill_between(np.log(size_list), np.log(PDASGD_result_cleaned.groupby('n').min()['computations']),\n",
    "#         np.log(PDASGD_result_cleaned.groupby('n').max()['computations']),\n",
    "#         color='crimson', alpha = 0.2)\n",
    "\n",
    "plt.xlabel(r'$ln(n)$',fontsize=20)\n",
    "plt.ylabel(r'$ln( \\# operation )$',fontsize=20) \n",
    "plt.legend(fontsize=13)\n",
    "plt.title(\"ln(number of operations) versus ln(n)\",fontsize=20)\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "plt.savefig(\"results/mnist_compare_deter.pdf\", format=\"pdf\",bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 915
    },
    "executionInfo": {
     "elapsed": 4387,
     "status": "ok",
     "timestamp": 1648512604174,
     "user": {
      "displayName": "Mia L",
      "userId": "10188914046469678038"
     },
     "user_tz": 240
    },
    "id": "_eAtQ9lZtfLm",
    "outputId": "f5469725-67a3-4b06-d097-6956ecafeeda"
   },
   "outputs": [],
   "source": [
    "#%% plot the comparison with stochastic algorithms\n",
    "\n",
    "PDASGD_result_cleaned = pd.DataFrame([[i[0][1],i[0][2],i[1]] for i in zip(PDASGD_result,np.repeat(size_list, reps_each_m))])\n",
    "PDASGD_result_cleaned.columns = ['computations','time','n']\n",
    "\n",
    "\n",
    "Sto_Sink_result_cleaned = pd.DataFrame([[i[0][1],i[0][2],i[1]] for i in zip(Stoc_Sinkhorn_result,np.repeat(size_list, reps_each_m))])\n",
    "Sto_Sink_result_cleaned.columns = ['computations','time','n']\n",
    "#%%\n",
    "\n",
    "plt.figure(dpi=1000)\n",
    "\n",
    "\n",
    "lr_smd  = linregress(np.log(size_list), np.log(PDASMD_result_cleaned.groupby('n').mean()['computations']))\n",
    "plt.plot(np.log(size_list), np.log(PDASMD_result_cleaned.groupby('n').mean()['computations']),\n",
    "         label=\"PDASMD, slope = {:.2f}\".format(lr_smd[0]),color='darkgreen', marker ='o',markersize = 6,lw=1)\n",
    "plt.fill_between(np.log(size_list), np.log(PDASMD_result_cleaned.groupby('n').min()['computations']),\n",
    "         np.log(PDASMD_result_cleaned.groupby('n').max()['computations']),\n",
    "         color='darkgreen', alpha = 0.2)\n",
    "\n",
    "lr_sgd  = linregress(np.log(size_list), np.log(PDASGD_result_cleaned.groupby('n').mean()['computations']))\n",
    "plt.plot(np.log(size_list), np.log(PDASGD_result_cleaned.groupby('n').mean()['computations']),\n",
    "         label=\"PDASGD, slope = {:.2f}\".format(lr_sgd[0]),color='pink', marker ='*',markersize = 6,lw=1)\n",
    "plt.fill_between(np.log(size_list), np.log(PDASGD_result_cleaned.groupby('n').min()['computations']),\n",
    "         np.log(PDASGD_result_cleaned.groupby('n').max()['computations']),\n",
    "         color='pink', alpha = 0.2)\n",
    "\n",
    "\n",
    "lr_ss  = linregress(np.log(size_list), np.log(Sto_Sink_result_cleaned.groupby('n').mean()['computations']))\n",
    "plt.plot(np.log(size_list), np.log(Sto_Sink_result_cleaned.groupby('n').mean()['computations']),\n",
    "         label=\"Stochastic Sinkhorn, slope = {:.2f}\".format(lr_ss[0]),color='violet', marker ='o',markersize = 6,lw=1)\n",
    "plt.fill_between(np.log(size_list), np.log(Sto_Sink_result_cleaned.groupby('n').min()['computations']),\n",
    "         np.log(Sto_Sink_result_cleaned.groupby('n').max()['computations']),\n",
    "         color='violet', alpha = 0.2)\n",
    "\n",
    "\n",
    "plt.xlabel(r'$ln(n)$',fontsize=20)\n",
    "plt.ylabel(r'$ln( \\# operation )$',fontsize=20) \n",
    "plt.legend(fontsize=13)\n",
    "plt.title(\"ln(number of operations) versus ln(n)\",fontsize=20)\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "plt.savefig(\"results/mnist_compare_stoc.pdf\", format=\"pdf\",bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY_ECUj0TY-K"
   },
   "source": [
    "#4. Evaluate PDASMD-B on MNIST data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jo3CNVgDUGrI"
   },
   "outputs": [],
   "source": [
    "# sample and rescale the images as marginal\n",
    "alpha_list = []\n",
    "beta_list = []\n",
    "C_list = []\n",
    "m_list = [7,8,10]\n",
    "size_list = list(map(lambda x: x**2,m_list))\n",
    "reps_each_m = 5\n",
    "num_m = len(m_list)\n",
    "\n",
    "np.random.seed(1001)\n",
    "idx_list_1 = np.random.choice(range(30000),reps_each_m)\n",
    "idx_list_2 = np.random.choice(range(30000,60000),reps_each_m)\n",
    "\n",
    "#### marginal distribution list, where we reshape the mnist image to get different size marginals\n",
    "for m in m_list:\n",
    "    for idx1,idx2 in zip(idx_list_1,idx_list_2):\n",
    "      fig1 = Image.fromarray(x_train[idx1]).resize((m,m)) ### down scale the images\n",
    "      fig2 = Image.fromarray(x_train[idx2]).resize((m,m)) \n",
    "      fig1 = np.array(fig1, np.float64)\n",
    "      fig2 = np.array(fig2, np.float64) \n",
    "      idx = np.where(fig1 <= .15* np.max(fig1)) \n",
    "      fig1[idx] = .15* np.max(fig1) ### add background intensity\n",
    "      idx = np.where(fig2 <= .15* np.max(fig2)) \n",
    "      fig2[idx] = .15* np.max(fig2) ### add background intensity\n",
    "      fig1 /= fig1.sum()\n",
    "      fig2 /= fig2.sum()\n",
    "\n",
    "      alpha_list.append(fig1.reshape(-1,1)) \n",
    "      beta_list.append(fig2.reshape(-1,1)) \n",
    "    \n",
    "    C_list.append(dist_img_m(m))\n",
    "\n",
    "#%%% parameter list\n",
    "epsilons = [.1] * reps_each_m * num_m\n",
    "sizes = np.repeat(size_list, reps_each_m)\n",
    "idxes_c = np.repeat(range(num_m), reps_each_m)\n",
    "idxes_dist = range(num_m * reps_each_m)\n",
    "\n",
    "batch_sizes = [i for i in range(2,49,8)]\n",
    "\n",
    "settings = []\n",
    "for epsilon, size, idx_c, idx_dist in list(zip(epsilons,sizes,idxes_c,idxes_dist)):\n",
    "    for batch_size in batch_sizes:\n",
    "        settings.append([epsilon, size, idx_c, idx_dist, batch_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXky2XQeUHUG"
   },
   "outputs": [],
   "source": [
    "#%% calculate epsilon solution, the goal is to compare the total computation\n",
    "PDASMD_result_batch = []\n",
    "i = 1\n",
    "for epsilon, size, idx_c, idx_dist, batch_size in settings:\n",
    "    print(\"Running {}/{} experiment\".format(i,len(settings)))\n",
    "    i += 1\n",
    "    solution, computations, time = PDASMD_w_rounding(\n",
    "        alpha = alpha_list[idx_dist], beta = beta_list[idx_dist],\n",
    "        C = C_list[idx_c], epsilon = epsilon, Size = size, \n",
    "        inner_iters = size//batch_size, batchsize = batch_size, MD = True)\n",
    "    PDASMD_result_batch.append([solution, computations, time])\n",
    "\n",
    "\n",
    "#%%plot the results\n",
    "PDASMD_result_batch_cleaned = pd.DataFrame([[i[0][1],i[0][2],i[1][1],i[1][4]] for i in zip(PDASMD_result_batch,settings)])\n",
    "PDASMD_result_batch_cleaned.columns = ['computations','time','n','batchsize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11lPf_dYUI_H"
   },
   "outputs": [],
   "source": [
    "#%% Plot the results\n",
    "plt.figure(dpi=1000)\n",
    "\n",
    "PDASMD_result_batch_mean = np.log(PDASMD_result_batch_cleaned.groupby(['n','batchsize']).mean()['computations'])\n",
    "PDASMD_result_batch_min = np.log(PDASMD_result_batch_cleaned.groupby(['n','batchsize']).min()['computations'])\n",
    "PDASMD_result_batch_max = np.log(PDASMD_result_batch_cleaned.groupby(['n','batchsize']).max()['computations'])\n",
    "#%%\n",
    "for n in size_list:\n",
    "    lr  = linregress(np.log(batch_sizes),PDASMD_result_batch_mean.loc[n] )\n",
    "    \n",
    "    plt.plot(np.log(batch_sizes), PDASMD_result_batch_mean.loc[n],label=\"n = {}, slope = {:.2f}\".format(n,lr[0]), marker ='o',markersize = 6,lw=1)\n",
    "    plt.fill_between(np.log(batch_sizes),PDASMD_result_batch_min.loc[n] ,\n",
    "             PDASMD_result_batch_max.loc[n], alpha = 0.2)\n",
    "\n",
    "plt.xlabel(r'$ln(batchsize)$',fontsize=20)\n",
    "plt.ylabel(r'$ln( \\# operation )$',fontsize=20) \n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"ln(number of operations) versus ln(batchsize)\",fontsize=20)\n",
    "\n",
    "plt.savefig(\"results/mnist_batch_computation.pdf\", format=\"pdf\", bbox_inches = 'tight')\n",
    "\n",
    "#%%\n",
    "\n",
    "plt.figure(dpi=1000)\n",
    "PDASMD_result_batch_mean = np.log(PDASMD_result_batch_cleaned.groupby(['n','batchsize']).mean()['time'])\n",
    "PDASMD_result_batch_min = np.log(PDASMD_result_batch_cleaned.groupby(['n','batchsize']).min()['time'])\n",
    "PDASMD_result_batch_max = np.log(PDASMD_result_batch_cleaned.groupby(['n','batchsize']).max()['time'])\n",
    "\n",
    "for n in size_list:\n",
    "    plt.plot(np.log(batch_sizes), PDASMD_result_batch_mean.loc[n],label=\"n = {}, slope = {:.2f}\".format(n,lr[0]), marker ='o',markersize = 6,lw=1)\n",
    "    plt.fill_between(np.log(batch_sizes),PDASMD_result_batch_min.loc[n] ,\n",
    "             PDASMD_result_batch_max.loc[n], alpha = 0.2)\n",
    "    \n",
    "plt.xlabel(r'$ln(batchsize)$',fontsize=20)\n",
    "plt.ylabel(r'$ln(running time)$',fontsize=20) \n",
    "plt.legend(fontsize=20)\n",
    "plt.title(\"ln(running time) versus ln(batchsize)\",fontsize=20)\n",
    "\n",
    "\n",
    "plt.savefig(\"results/mnist_batch_time.pdf\", format=\"pdf\", bbox_inches = 'tight')\n",
    "\n",
    "#%% save the data and results\n",
    "\n",
    "results = {'alpha_list': alpha_list, 'beta_list': beta_list, 'C_list': C_list, \n",
    "    'PDASMD_result_batch': PDASMD_result_batch}\n",
    "  \n",
    "try:\n",
    "    file = open('results/comparison_mnist_batch', 'wb')\n",
    "    pickle.dump(results,file)\n",
    "    file.close()\n",
    "  \n",
    "except:\n",
    "    print(\"Something went wrong\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNeJrORjVdqkrhw6PzxTcnE",
   "collapsed_sections": [
    "Oj71ZXhGTOtD",
    "vY_ECUj0TY-K"
   ],
   "mount_file_id": "1DOS8CGwoaoxQHRyytxwFv-Eb1kRe649U",
   "name": "run_experiment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
